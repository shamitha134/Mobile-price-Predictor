# -*- coding: utf-8 -*-
"""MINOR_PROJECT.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1s6QDqo5UqhP4oEHEftygLPJgi3ehsRJn
"""

'''importing the required libraries''' 
import pandas as pd                   # For data manipulation and analysis.
import numpy as np                    # For scientific computing in Python
import matplotlib.pyplot as plt       # Plotting library for Python
import seaborn as sns                 # Data visualization library based on matplotlib for Python

#Reading the csv file
df = pd.read_csv('mobile_price_range_data (1).csv')
df.head()   #displays the first 5 records in the csv file

#To display the last 5 records in the csv file
df.tail()

#To display the number of rows and columns
df.shape

#To display the datatype for each column 
df.dtypes

#To check if there are any null values present
df.isnull().sum()

"""***DATA DISTRIBUTION***


---
Analysing some data features and seeing their distribution.

"""

#To plot the bar graph for price range against count values 
#i.e., the graph shows the count of mobile phones in the respective price ranges

sns.set()
price_plot=df['price_range'].value_counts().plot(kind='bar')
plt.xlabel('price_range')
plt.ylabel('Count')
plt.show()

"""**displot** function, that is used below, provides access to several approaches for visualizing the univariate or bivariate distribution of data"""

#To display the no. of mobile phones according to their battery power 

sns.set(rc={'figure.figsize':(5,5)})
ax1=sns.displot(data=df["battery_power"])

#To know the count of mobile phones based on whether or not they have dual sim

sns.set(rc={'figure.figsize':(5,5)})
ax2=sns.displot(data=df["dual_sim"])

#To know the count of mobile phones with respect to their internal memory space

sns.set(rc={'figure.figsize':(5,5)})
ax3=sns.displot(data=df["int_memory"])

#To know the count of mobile phones based on their clock speed

sns.set(rc={'figure.figsize':(5,5)})
ax3=sns.displot(data=df["clock_speed"])

#To display the scatterplot of battery_power vs dual_sim by color coding them with respect to the price_range

sns.set(rc={'figure.figsize':(10,10)})
sns.scatterplot(df['battery_power'],df['dual_sim'],hue=df['price_range'],palette='rainbow')
plt.show()

# Define x (independent variables) and y (depedent variable)
x = df.iloc[:,:-1]
y = df.iloc[:,-1]

print(x.shape)
print(y.shape)

#to view the type of variables 
print(type(x))
print(type(y))

#Splitting data into train and test datasets

from sklearn.model_selection import train_test_split
x_tr,x_te,y_tr,y_te = train_test_split(x,y,test_size=0.25)
print(x_tr.shape)
print(x_te.shape)
print(y_tr.shape)
print(y_te.shape)

"""***Building the model***

---



***a)LOGISTIC REGRESSION***<br>Logistic regression is one of the Machine Learning algorithms, which comes under the Supervised Learning technique. It is used for predicting variable.or predicting the categorical dependent variable using a given set of independent variables. Logistic regression predicts the output of a categorical dependent variable.





"""

# Importing LogisticRegression class from sklearn library

from sklearn.linear_model import LogisticRegression

m1 = LogisticRegression()  # Creating object for the model class
m1.fit(x_tr,y_tr)          # fitting the model on to the training data (or) training the model

#To print the accuracy score for both training and testing datasets

print('Training Score',m1.score(x_tr,y_tr))
print('Testing Score',m1.score(x_te,y_te))

# To generate the predicted values for testing dataset through logistic regression model                

ypredLR = m1.predict(x_te)  
print(ypredLR)

# To create a dataframe for comparing the actual values and predicted values

res1 = pd.DataFrame({'Actual Value':y_te,'Predicted value':ypredLR})
print(res1.tail())

#Generating Confusion matrix and Classification report

# A confusion matrix is a table that is often used to describe the performance of a classification model on a set of test data for which the true values are known.
# A classification report is a performance evaluation metric in machine learning to show the precision, recall, F1 Score, and support of your trained classification model.

from sklearn.metrics import confusion_matrix,classification_report

print('CONFUSION MATRIX :')
cm_LR = confusion_matrix(y_te,ypredLR)
print(cm_LR)
print(' ')
print('CLASSIFICATION REPORT :')
cr_LR = classification_report(y_te,ypredLR)
print(cr_LR)

# To generate intercept/constant and coefficient/slope values

a1 = m1.coef_
b1 = m1.intercept_
print("Coefficient or slope",a1)
print("Intercept or Constant",b1)

"""**b) KNN CLASSIFICATION** <br> The k-nearest neighbors (KNN) algorithm is a simple, supervised machine learning algorithm that can be used to solve both classification and regression problems."""

# Importing KNeighborsClassifier class from sklearn library

from sklearn.neighbors import KNeighborsClassifier
m2 = KNeighborsClassifier(n_neighbors=245)    # Creating object for the model class and specifying the K value i.e., the number of nearest neighbors
m2.fit(x_tr,y_tr)                             # fitting the model on to the training data (or) training the model

#To print the accuracy score for both training and testing datasets

print('Training Score',m2.score(x_tr,y_tr))
print('Testing Score',m2.score(x_te,y_te))

# To generate the predicted values for testing dataset through KNN classification model 

ypredKN = m2.predict(x_te)
print(ypredKN)

# To create a dataframe for comparing the actual values and predicted values

res2 = pd.DataFrame({'Actual Value':y_te,'Predicted value':ypredKN})
print(res2)

#Generating Confusion matrix

cm_KN = confusion_matrix(y_te,ypredKN)
print(cm_KN)

#Generating Classification report

cr_KN = classification_report(y_te,ypredKN)
print(cr_KN)

"""**c)SVM Classification**<br>Support Vector Machine (SVM) is a supervised classification technique used for the classification of linear as well as non-linear data.<br>
SVM takes these data points and outputs the hyperplane (in two dimensions it's simply a line) that best separates the data. 
"""

# Importing SVC class from sklearn library

from sklearn.svm import SVC

'''linear kernel'''
s1 = SVC(kernel='linear',C=1)   # Creating object for the model class with LINEAR kernel
s1.fit(x_tr,y_tr)               # fitting the model on to the training data (or) training the model

# To print the accuracy score for both training and testing datasets

print('Training Score',s1.score(x_tr,y_tr))
print('Testing Score',s1.score(x_te,y_te))

# To generate the predicted values for testing dataset through SVM classification model with linear kernel

ypred_s1 = s1.predict(x_te)
print(ypred_s1)

# To create a dataframe for comparing the actual values and predicted values

res_s1 = pd.DataFrame({'Actual_Value':y_te,'Predicted_Value':ypred_s1 })
res_s1.head()

#Generating Confusion matrix

cm_s1 = confusion_matrix(y_te,ypred_s1)
print(cm_s1)

#Generating Classification report

cr_s1 = classification_report(y_te,ypred_s1)
print(cr_s1)

'''rbf kernel'''
s2 = SVC(kernel='rbf',gamma=0.00001,C=1)    # Creating object for the model class with rbf kernel
# gamma is a parameter for non linear hyperplanes. The gamma parameter defines how far the influence of a single training example reaches.

s2.fit(x_tr,y_tr)                           # fitting the model on to the training data (or) training the model

#To print the accuracy score for both training and testing datasets

print('Training Score',s2.score(x_tr,y_tr))
print('Testing Score',s2.score(x_te,y_te))

# To generate the predicted values for testing dataset through SVM classification model with rbf kernel 

ypred_s2 = s2.predict(x_te)
print(ypred_s2)

# To create a dataframe for comparing the actual values and predicted values
# through SVM classification model with rbf kernel

res_s2 = pd.DataFrame({'Actual_Value':y_te,'Predicted_Value':ypred_s2})
res_s2.head()

#Generating Confusion matrix

cm_s2 = confusion_matrix(y_te,ypred_s2)
print(cm_s2)

#Generating Classification report

cr_s2 = classification_report(y_te,ypred_s2)
print(cr_s2)

"""***CONCLUSION :*** 

---

**Hence we can see that SVM model produces best 
accuracy among the above classification models**.SVM classifier model with linear kernal performs more efficiently.
"""